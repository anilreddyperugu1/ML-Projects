# ğŸŒ¸ Clustering the Iris Dataset using PCA & Logistic Regression ğŸŒ¿  

A ğŸŒ¼ machine learning project that applies **Principal Component Analysis (PCA)** for dimensionality reduction and then uses **Logistic Regression** for classification.  This project demonstrates how PCA can simplify high-dimensional data while preserving its essence ğŸ’¡ for effective classification. Let's dive in ğŸš€

---

## ğŸ“œ Index  
1. ğŸ“Œ [Project Overview](#-project-overview)  
2. ğŸ¯ [Problem Statement](#-problem-statement)  
3. ğŸ“š [Key Features & Terminologies](#-key-features--terminologies)  
4. ğŸ”„ [Workflow Summary](#-workflow-summary)  
5. ğŸ“Š [Model Evaluation](#-model-evaluation)  
6. ğŸ¯ [Key Takeaways](#-key-takeaways)  
---

## ğŸ“Œ Project Overview  
The goal ğŸ¯ of this project is to **cluster** the famous Iris dataset ğŸŒ¸ into meaningful groups using **unsupervised learning**.  
We first reduce the dataset from 4ï¸âƒ£ features to 2ï¸âƒ£ principal components using PCA ğŸ¨ and then apply **Logistic Regression** ğŸ¤– for classification.

---

## â“ Problem Statement  
The Iris dataset has **four features** ğŸ“ (sepal length, sepal width, petal length, petal width).  
Visualizing and clustering directly in 4D is hard ğŸŒ€, so we need a method to reduce the complexity without losing key patterns ğŸŒŸ.  
PCA helps us convert these 4D data points into **2 principal components** ğŸ” for easy visualization and better clustering.

---

## ğŸ“š Key Features & Terminologies  
- PCA (Principal Component Analysis) ğŸ—œï¸ â†’ Reduces the number of features while retaining most of the data's variance ğŸ“‰.

- Logistic Regression ğŸ¤– â†’ A supervised learning algorithm for classification problems ğŸ“š.

- Explained Variance Ratio ğŸ“Š â†’ Shows how much information (variance) each principal component holds.

- Confusion Matrix ğŸ§® â†’ Gives insight into correct vs incorrect predictions.

- Accuracy, Precision, Recall, F1-Score ğŸ“ â†’ Metrics to evaluate classification performance.

---

## ğŸ”„ Workflow Summary  

1. **ğŸ“¥ Load Data**  
   - Imported the **Iris dataset** ğŸŒ¸ from `sklearn.datasets`.  

2. **ğŸ§¹ Data Preprocessing**  
   - Scaled features using **StandardScaler** âš–ï¸ to give equal weight to all measurements.

3. **ğŸ” Apply PCA**  
   - Reduced from 4ï¸âƒ£ features â†’ 2ï¸âƒ£ principal components ğŸ“‰.  
   - First component captures ğŸŒŸ maximum variance, second captures the next most variance.  
   - Explained variance ratio showed **how much info we kept** (~95% retained ğŸ“Š).    

5. **ğŸ“ˆ Visualization**  
   - Scatter plot ğŸ¨ of principal components with colors ğŸ¨ for clusters.  
   - Highlighted **cluster centers** âœ¨ for better understanding.  

---

## ğŸ“Š Model Evaluation
Accuracy ğŸ†: 0.9âœ…

---

## ğŸ¯ Key Takeaways  
- PCA ğŸ¨ is a **helper tool** that reduces complexity and makes clustering easier & more accurate ğŸš€.  
- High explained variance ratio ğŸ’¯ means PCA kept most of the original dataâ€™s information.   
- Visualization in 2D becomes much more interpretable after PCA ğŸ“‰.

---

## ğŸ“‡ Author

Anil Reddy PeruguğŸ’

ğŸ“§ Email: peruguanilreddy6@gmail.com

ğŸ“ Feel free to reach out for queries, suggestions, or collaborations!

